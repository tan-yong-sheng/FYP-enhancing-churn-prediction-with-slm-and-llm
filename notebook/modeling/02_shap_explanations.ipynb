{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a69a63dc",
   "metadata": {},
   "source": [
    "# Evaluation on LLM-generated narratives for SHAP explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1355dc84",
   "metadata": {},
   "source": [
    "## Part 1: Data loading & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70753b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the cleaned data\n",
    "import pandas as pd\n",
    "\n",
    "merged_data_final = pd.read_csv(\"../../data/processed/cleaned_data.csv.gz\", compression=\"gzip\")\n",
    "\n",
    "X = merged_data_final.drop(['churn_risk_score'], axis = 1)\n",
    "y = merged_data_final['churn_risk_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f4870e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "                    X, y, train_size=0.6, \n",
    "                    stratify= y,\n",
    "                    random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "                    X_temp, y_temp, train_size=0.5,\n",
    "                    stratify=y_temp,\n",
    "                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92405feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export train and test dataset to `data` folder\n",
    "pd.concat([X_train, y_train], axis=1).to_csv(\"../../data/input/train.csv.gz\", index=False)\n",
    "pd.concat([X_valid, y_valid], axis=1).to_csv(\"../../data/input/valid.csv.gz\", index=False)\n",
    "pd.concat([X_test, y_test], axis=1).to_csv(\"../../data/input/test.csv.gz\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414654d8",
   "metadata": {},
   "source": [
    "### Prepare Structured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49807123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training structured data shape: (22194, 22)\n",
      "Training target shape: (22194,)\n",
      "Training structured columns: ['gender_M', 'region_category_Town', 'region_category_Village', 'joined_through_referral_Yes', 'preferred_offer_types_Gift Vouchers/Coupons', 'preferred_offer_types_Without Offers', 'medium_of_operation_Desktop', 'medium_of_operation_Smartphone', 'internet_option_Mobile_Data', 'internet_option_Wi-Fi', 'used_special_discount_Yes', 'offer_application_preference_Yes', 'past_complaint_Yes', 'years_since_joining', 'membership_category', 'complaint_status', 'age', 'days_since_last_login', 'avg_time_spent', 'avg_transaction_value', 'avg_frequency_login_days', 'points_in_wallet']\n"
     ]
    }
   ],
   "source": [
    "# Prepare structured training data\n",
    "X_train_structured_with_id = X_train.copy()\n",
    "X_train_structured = X_train_structured_with_id.drop(columns=[\"id\", \"feedback\"])\n",
    "\n",
    "print(f\"Training structured data shape: {X_train_structured.shape}\")\n",
    "print(f\"Training target shape: {y_train.shape}\")\n",
    "print(f\"Training structured columns: {list(X_train_structured.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8f0bb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation structured data shape: (7398, 22)\n",
      "Validation target shape: (7398,)\n",
      "Validation structured columns: ['gender_M', 'region_category_Town', 'region_category_Village', 'joined_through_referral_Yes', 'preferred_offer_types_Gift Vouchers/Coupons', 'preferred_offer_types_Without Offers', 'medium_of_operation_Desktop', 'medium_of_operation_Smartphone', 'internet_option_Mobile_Data', 'internet_option_Wi-Fi', 'used_special_discount_Yes', 'offer_application_preference_Yes', 'past_complaint_Yes', 'years_since_joining', 'membership_category', 'complaint_status', 'age', 'days_since_last_login', 'avg_time_spent', 'avg_transaction_value', 'avg_frequency_login_days', 'points_in_wallet']\n"
     ]
    }
   ],
   "source": [
    "# Prepare structured validation data\n",
    "X_valid_structured_with_id = X_valid.copy()\n",
    "X_valid_structured = X_valid_structured_with_id.drop(columns=[\"id\", \"feedback\"])\n",
    "\n",
    "print(f\"Validation structured data shape: {X_valid_structured.shape}\")\n",
    "print(f\"Validation target shape: {y_valid.shape}\")\n",
    "print(f\"Validation structured columns: {list(X_valid_structured.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dab5558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test structured data shape: (7399, 22)\n",
      "Test target shape: (7399,)\n",
      "Test structured columns: ['gender_M', 'region_category_Town', 'region_category_Village', 'joined_through_referral_Yes', 'preferred_offer_types_Gift Vouchers/Coupons', 'preferred_offer_types_Without Offers', 'medium_of_operation_Desktop', 'medium_of_operation_Smartphone', 'internet_option_Mobile_Data', 'internet_option_Wi-Fi', 'used_special_discount_Yes', 'offer_application_preference_Yes', 'past_complaint_Yes', 'years_since_joining', 'membership_category', 'complaint_status', 'age', 'days_since_last_login', 'avg_time_spent', 'avg_transaction_value', 'avg_frequency_login_days', 'points_in_wallet']\n"
     ]
    }
   ],
   "source": [
    "# Prepare structured test data\n",
    "X_test_structured_with_id = X_test.copy()\n",
    "X_test_structured = X_test_structured_with_id.drop(columns=[\"id\", \"feedback\"])\n",
    "\n",
    "print(f\"Test structured data shape: {X_test_structured.shape}\")\n",
    "print(f\"Test target shape: {y_test.shape}\")\n",
    "print(f\"Test structured columns: {list(X_test_structured.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b5ea4",
   "metadata": {},
   "source": [
    "### Pick the best model - \"XGBoost with Structured Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "821c6e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0000\n",
      "Valid Accuracy:  0.9258\n",
      "Test Accuracy:  0.9311\n",
      "\n",
      "Train F1-score: 1.0000\n",
      "Valid F1-score:  0.9256\n",
      "Test F1-score:  0.9310\n",
      "\n",
      "Train Precision: 1.0000\n",
      "Valid Precision:  0.9265\n",
      "Test Precision:  0.9314\n",
      "\n",
      "Train Recall: 1.0000\n",
      "Valid Recall:  0.9258\n",
      "Test Recall:  0.9311\n",
      "\n",
      "Classification Report (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92      3396\n",
      "           1       0.92      0.95      0.94      4003\n",
      "\n",
      "    accuracy                           0.93      7399\n",
      "   macro avg       0.93      0.93      0.93      7399\n",
      "weighted avg       0.93      0.93      0.93      7399\n",
      "\n",
      "Confusion Matrix (Test):\n",
      "[[3077  319]\n",
      " [ 191 3812]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import (f1_score, accuracy_score, precision_score, \n",
    "                            recall_score, classification_report, confusion_matrix)\n",
    "\n",
    "# Train the model\n",
    "xgb_model = xgb.XGBClassifier(max_depth=10,\n",
    "                            random_state=42,\n",
    "                            # Introduce randomness to make training faster and reduce overfitting\n",
    "                            subsample=0.8, ## Uses 80% of the data for each tree.\n",
    "                            colsample_bytree=0.8, ## Uses 80% of the features for each tree.\n",
    "                            # the parameters below make the model trained faster by enabling parallelism\n",
    "                            n_jobs = -1)\n",
    "xgb_model.fit(X_train_structured, y_train)\n",
    "\n",
    "# Predictions on training and test sets\n",
    "y_train_pred_xgb = xgb_model.predict(X_train_structured)\n",
    "y_valid_pred_xgb = xgb_model.predict(X_valid_structured)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test_structured)\n",
    "\n",
    "# Accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred_xgb)\n",
    "valid_accuracy = accuracy_score(y_valid, y_valid_pred_xgb)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_xgb)\n",
    "\n",
    "# F1 scores\n",
    "train_f1_score = f1_score(y_train, y_train_pred_xgb, average='weighted')\n",
    "valid_f1_score = f1_score(y_valid, y_valid_pred_xgb, average='weighted')\n",
    "test_f1_score = f1_score(y_test, y_test_pred_xgb, average='weighted')\n",
    "\n",
    "# Precision scores\n",
    "train_precision = precision_score(y_train, y_train_pred_xgb, average='weighted')\n",
    "valid_precision = precision_score(y_valid, y_valid_pred_xgb, average='weighted')\n",
    "test_precision = precision_score(y_test, y_test_pred_xgb, average='weighted')\n",
    "\n",
    "# Recall scores\n",
    "train_recall = recall_score(y_train, y_train_pred_xgb, average='weighted')\n",
    "valid_recall = recall_score(y_valid, y_valid_pred_xgb, average='weighted')\n",
    "test_recall = recall_score(y_test, y_test_pred_xgb, average='weighted')\n",
    "\n",
    "# Output\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Valid Accuracy:  {valid_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_accuracy:.4f}\\n\")\n",
    "\n",
    "print(f\"Train F1-score: {train_f1_score:.4f}\")\n",
    "print(f\"Valid F1-score:  {valid_f1_score:.4f}\")\n",
    "print(f\"Test F1-score:  {test_f1_score:.4f}\\n\")\n",
    "\n",
    "print(f\"Train Precision: {train_precision:.4f}\")\n",
    "print(f\"Valid Precision:  {valid_precision:.4f}\")\n",
    "print(f\"Test Precision:  {test_precision:.4f}\\n\")\n",
    "\n",
    "print(f\"Train Recall: {train_recall:.4f}\")\n",
    "print(f\"Valid Recall:  {valid_recall:.4f}\")\n",
    "print(f\"Test Recall:  {test_recall:.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report (Test):\")\n",
    "print(classification_report(y_test, y_test_pred_xgb))\n",
    "\n",
    "print(\"Confusion Matrix (Test):\")\n",
    "print(confusion_matrix(y_test, y_test_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7b413",
   "metadata": {},
   "source": [
    "## Part 2: Generate SHAP explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109efaf6",
   "metadata": {},
   "source": [
    "### 2.1 Prepare SHAP values to be feed into LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b1c6bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP values calculated\n",
      "SHAP values shape: (30, 22)\n",
      "Sampled data shape: (30, 22)\n",
      "Columns used for SHAP: ['gender_M', 'region_category_Town', 'region_category_Village', 'joined_through_referral_Yes', 'preferred_offer_types_Gift Vouchers/Coupons', 'preferred_offer_types_Without Offers', 'medium_of_operation_Desktop', 'medium_of_operation_Smartphone', 'internet_option_Mobile_Data', 'internet_option_Wi-Fi', 'used_special_discount_Yes', 'offer_application_preference_Yes', 'past_complaint_Yes', 'years_since_joining', 'membership_category', 'complaint_status', 'age', 'days_since_last_login', 'avg_time_spent', 'avg_transaction_value', 'avg_frequency_login_days', 'points_in_wallet']\n"
     ]
    }
   ],
   "source": [
    "# Calculate SHAP values for the test data\n",
    "import shap\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "n_samples = 30\n",
    "\n",
    "# Extract the model from the pipeline\n",
    "best_model = xgb_model\n",
    "\n",
    "# Create SHAP TreeExplainer using the extracted model\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "\n",
    "# Perform stratified sampling on the test data to select 'n_samples' instances\n",
    "# Use the structured data with ID for sampling, then get the same samples from structured data\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=n_samples, random_state=42)\n",
    "for _, test_index in sss.split(X_test_structured, y_test):\n",
    "    X_test_sampled_with_id = X_test_structured_with_id.iloc[test_index]\n",
    "    X_test_sampled_structured = X_test_structured.iloc[test_index]\n",
    "\n",
    "# Calculate SHAP values using structured data without 'id' and 'feedback'\n",
    "shap_values = explainer.shap_values(X_test_sampled_structured)\n",
    "expected_value = explainer.expected_value\n",
    "\n",
    "print(\"SHAP values calculated\")\n",
    "print(f\"SHAP values shape: {shap_values.shape}\")\n",
    "print(f\"Sampled data shape: {X_test_sampled_structured.shape}\")\n",
    "print(f\"Columns used for SHAP: {list(X_test_sampled_structured.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d18e012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SHAP structures for 30 customers\n",
      "Example SHAP features: ['gender_M', 'region_category_Town', 'region_category_Village', 'joined_through_referral_Yes', 'preferred_offer_types_Gift Vouchers/Coupons']\n"
     ]
    }
   ],
   "source": [
    "# Convert SHAP values to DataFrame for easier manipulation\n",
    "shap_df = pd.DataFrame(shap_values, columns=X_test_sampled_structured.columns)\n",
    "\n",
    "# Add 'id' column to shap_df for alignment\n",
    "shap_df['id'] = X_test_sampled_with_id['id'].values\n",
    "\n",
    "# Reset index to ensure clean iteration\n",
    "shap_df = shap_df.reset_index(drop=True)\n",
    "\n",
    "# Initialize a dictionary to store the JSON structures\n",
    "json_structures = {}\n",
    "\n",
    "# Generate a JSON structure for each row in shap_df\n",
    "for index, row in shap_df.iterrows():\n",
    "    # Create a dictionary for the current row\n",
    "    row_dict = row.to_dict()\n",
    "\n",
    "    # Use id as the key for the JSON structure and remove it from the values\n",
    "    customer_id = row_dict.pop('id')\n",
    "    json_structures[customer_id] = row_dict\n",
    "\n",
    "print(f\"Generated SHAP structures for {len(json_structures)} customers\")\n",
    "print(f\"Example SHAP features: {list(list(json_structures.values())[0].keys())[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62e561cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_and_get_top_features(features):\n",
    "    sorted_features = sorted(features.items(), key=lambda item: abs(item[1]), reverse=True)\n",
    "    top_features = sorted_features[:10]\n",
    "    return top_features \n",
    "\n",
    "# Create an empty DataFrame\n",
    "features_shap_values = pd.DataFrame()\n",
    "\n",
    "# Iterate over each ID key\n",
    "for id_key, features in json_structures.items():\n",
    "    sorted_features_df = sort_and_get_top_features(features)\n",
    "    keys = [key for key, _ in sorted_features_df]\n",
    "    values = [value for _, value in sorted_features_df]\n",
    "    features_shap_values = pd.concat([features_shap_values, pd.DataFrame({\"ID\": id_key,\n",
    "                                                                          \"top10_feature\": [keys],\n",
    "                                                                          \"top10_shap_values\":[values]})])\n",
    "                                     \n",
    "features_shap_values = features_shap_values.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2df494b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample combined data:\n",
      "Keys: ['gender_M', 'region_category_Town', 'region_category_Village', 'joined_through_referral_Yes', 'preferred_offer_types_Gift Vouchers/Coupons', 'preferred_offer_types_Without Offers', 'medium_of_operation_Desktop', 'medium_of_operation_Smartphone', 'internet_option_Mobile_Data', 'internet_option_Wi-Fi', 'used_special_discount_Yes', 'offer_application_preference_Yes', 'past_complaint_Yes', 'id', 'years_since_joining', 'membership_category', 'complaint_status', 'feedback', 'age', 'days_since_last_login', 'avg_time_spent', 'avg_transaction_value', 'avg_frequency_login_days', 'points_in_wallet', 'prediction_label', 'prediction_score_0', 'prediction_score_1']\n",
      "Prediction label: 0\n",
      "Sample features: [('gender_M', 1), ('region_category_Town', 0), ('region_category_Village', 0), ('joined_through_referral_Yes', 0), ('preferred_offer_types_Gift Vouchers/Coupons', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Combine predict and predict_proba in a DataFrame\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Predict labels and probabilities using structured data\n",
    "labels = xgb_model.predict(X_test_sampled_structured)\n",
    "proba = xgb_model.predict_proba(X_test_sampled_structured)\n",
    "\n",
    "# Create predictions DataFrame\n",
    "predictions = pd.DataFrame(proba, columns=[f\"prediction_score_{cls}\" for cls in xgb_model.classes_])\n",
    "predictions.insert(0, \"prediction_label\", labels)\n",
    "\n",
    "# Reset index if necessary (to ensure alignment during concat)\n",
    "X_test_sampled_with_id = X_test_sampled_with_id.reset_index(drop=True)\n",
    "predictions = predictions.reset_index(drop=True)\n",
    "\n",
    "# Combine features with predictions\n",
    "combined_df = pd.concat([X_test_sampled_with_id, predictions], axis=1)\n",
    "\n",
    "# Convert to JSON (list of dicts)\n",
    "parsed_json = json.loads(combined_df.to_json(orient='records'))\n",
    "\n",
    "# Example output\n",
    "print(\"Sample combined data:\")\n",
    "print(f\"Keys: {list(parsed_json[0].keys())}\")\n",
    "print(f\"Prediction label: {parsed_json[0]['prediction_label']}\")\n",
    "print(f\"Sample features: {[(k,v) for k,v in list(parsed_json[0].items())[:5]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81555a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_data(user_id, parsed_json, json_structures):\n",
    "    desired_data = next(item for item in parsed_json if item['id'] == int(user_id))\n",
    "\n",
    "    # get predicted_label from parsed_json\n",
    "    result = desired_data['prediction_label']\n",
    "    \n",
    "    shap_values = json_structures[int(user_id)]\n",
    "    \n",
    "    return result, shap_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c054c1",
   "metadata": {},
   "source": [
    "### 2.2 Prompt Template to generate narratives for SHAP explanations\n",
    "\n",
    "```markdown\n",
    "# System Prompt\n",
    "You are a churn explanation assistant. Provide clear, descriptive, business-oriented narratives that non-technical users can understand.\n",
    "\n",
    "# User Prompt\n",
    "The model predicted this customer will <CHURN_STATUS>.\n",
    "Top <TOP_N> features affecting the prediction:\n",
    "- <FEATURE_1>: <direction - in what direction it affects churn, either increase or decrease>, <magnitude - how strong the impact of the feature is> effect\n",
    "- <FEATURE_2>: <direction>, <magnitude> effect\n",
    "...\n",
    "- <FEATURE_N>: <direction>, <magnitude> effect\n",
    "\n",
    "Write a concise, business-friendly explanation for a non-technical user (50 words).  \n",
    "Describe why these features contribute to the prediction, using clear, empathetic language.  \n",
    "Do not use SHAP jargon or the phrase \"based on\".\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "For example:\n",
    "\n",
    "```markdown\n",
    "# System Prompt\n",
    "You are a churn explanation assistant. Provide clear, descriptive, business-oriented narratives that non-technical users can understand.\n",
    "\n",
    "# User Prompt\n",
    "The model predicted this customer will not churn.\n",
    "Top 5 features affecting the prediction:\n",
    "- Joined Through Referral Yes: decreases churn, very strong effect\n",
    "- Past Complaint Yes: increases churn, moderate effect\n",
    "- Membership Category: decreases churn, strong effect\n",
    "- Avg Frequency Login Days: decreases churn, strong effect\n",
    "- Points In Wallet: decreases churn, moderate effect\n",
    "\n",
    "Write a concise, business-friendly explanation for a non-technical user (50 words).  \n",
    "Describe why these features contribute to the prediction, using clear, empathetic language.  \n",
    "Do not use SHAP jargon or the phrase \"based on\".\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "369209d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, Any\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Feature magnitude mapping for SHAP values to reduce ambiguity\n",
    "def map_shap_magnitude(value):\n",
    "    abs_val = abs(value)\n",
    "    if abs_val > 5:\n",
    "        return \"very strong\"\n",
    "    elif abs_val > 1:\n",
    "        return \"strong\"\n",
    "    elif abs_val > 0.3:\n",
    "        return \"moderate\"\n",
    "    else:\n",
    "        return \"weak\"\n",
    "\n",
    "# Generate LLM-generated narratives for ML shap explanations\n",
    "def generate_churn_explainability(result: int, \n",
    "                                  shap_values: dict,\n",
    "                                  api_key: str,\n",
    "                                  top_n: int = 5, # Top 5 features are mentioned\n",
    "                                  model: str = \"gpt-4o-mini\",\n",
    "                                  temperature: float = 0.2,\n",
    "                                  show_prompt=False) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate churn explainability using OpenAI SDK directly\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize OpenAI client\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    \n",
    "    # Step 1: Select top features by absolute SHAP value\n",
    "    top_features = sorted(\n",
    "        shap_values.items(), key=lambda x: abs(x[1]), reverse=True\n",
    "    )[:top_n]\n",
    "\n",
    "    # Step 2: Preprocess features for LLM input with explicit ranking\n",
    "    feature_list: list[str] = []\n",
    "    for i, (feat, val) in enumerate(top_features, 1):\n",
    "        direction = \"increases churn\" if val > 0 else \"decreases churn\"\n",
    "        magnitude = map_shap_magnitude(val)\n",
    "        description = feat.replace(\"_\", \" \").title()\n",
    "        # Include ranking information to help with evaluation\n",
    "        feature_list.append(f\"- #{i} (MOST IMPORTANT): {description} - {direction}, {magnitude} effect (SHAP: {val:.3f})\" if i == 1 \n",
    "                          else f\"- #{i}: {description} - {direction}, {magnitude} effect (SHAP: {val:.3f})\")\n",
    "\n",
    "    feature_text = \"\\n\".join(feature_list)\n",
    "\n",
    "    explanation_prompt = f\"\"\"\n",
    "The model predicted this customer will {'churn' if result == 1 else 'not churn'}.\n",
    "Top {top_n} features affecting the prediction (ranked by importance, #1 is MOST important):\n",
    "{feature_text}\n",
    "\n",
    "Write a concise, business-friendly explanation for a non-technical user (50 words).\n",
    "IMPORTANT: Address features in order of their importance (#1 FIRST, then #2, etc.).\n",
    "Start with the most important factor (#1), then mention other key factors in descending order.\n",
    "Use clear, empathetic language and avoid SHAP jargon or the phrase \"based on\".\n",
    "\"\"\"\n",
    "\n",
    "    system_prompt = \"\"\"You are a churn explanation assistant. Provide clear, descriptive, business-oriented narratives that non-technical users can understand. \n",
    "\n",
    "CRITICAL: Always address the most important features first in your explanation. Follow the ranking order provided (#1, #2, #3, etc.). The #1 feature should be mentioned first and emphasized as the primary factor.\"\"\"\n",
    "    \n",
    "    if show_prompt is True:\n",
    "        print(\"PROMPT TEMPLATE FOR generate_churn_explainability function\")\n",
    "        print(\"===========\")\n",
    "        print(\"# System Prompt\")\n",
    "        print(system_prompt)\n",
    "        print(\"\\n# User Prompt\")\n",
    "        print(explanation_prompt)\n",
    "        print(\"===========\")\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": explanation_prompt}\n",
    "        ]\n",
    "    )\n",
    "    explanation = response.choices[0].message.content.strip()\n",
    "    \n",
    "    # Return results in the same format as the original function\n",
    "    return {\n",
    "        \"top_features\": feature_list,\n",
    "        'explanation': explanation\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a1171b",
   "metadata": {},
   "source": [
    "- Demo for the first row to `generate_churn_explainability`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85b52656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT TEMPLATE FOR generate_churn_explainability function\n",
      "===========\n",
      "# System Prompt\n",
      "You are a churn explanation assistant. Provide clear, descriptive, business-oriented narratives that non-technical users can understand. \n",
      "\n",
      "CRITICAL: Always address the most important features first in your explanation. Follow the ranking order provided (#1, #2, #3, etc.). The #1 feature should be mentioned first and emphasized as the primary factor.\n",
      "\n",
      "# User Prompt\n",
      "\n",
      "The model predicted this customer will not churn.\n",
      "Top 5 features affecting the prediction (ranked by importance, #1 is MOST important):\n",
      "- #1 (MOST IMPORTANT): Membership Category - decreases churn, very strong effect (SHAP: -8.528)\n",
      "- #2: Avg Frequency Login Days - decreases churn, strong effect (SHAP: -1.584)\n",
      "- #3: Age - increases churn, moderate effect (SHAP: 0.412)\n",
      "- #4: Used Special Discount Yes - increases churn, weak effect (SHAP: 0.183)\n",
      "- #5: Internet Option Wi-Fi - increases churn, weak effect (SHAP: 0.174)\n",
      "\n",
      "Write a concise, business-friendly explanation for a non-technical user (50 words).\n",
      "IMPORTANT: Address features in order of their importance (#1 FIRST, then #2, etc.).\n",
      "Start with the most important factor (#1), then mention other key factors in descending order.\n",
      "Use clear, empathetic language and avoid SHAP jargon or the phrase \"based on\".\n",
      "\n",
      "===========\n",
      "Demo: first row output\n",
      "{\n",
      "  \"top_features\": [\n",
      "    \"- #1 (MOST IMPORTANT): Membership Category - decreases churn, very strong effect (SHAP: -8.528)\",\n",
      "    \"- #2: Avg Frequency Login Days - decreases churn, strong effect (SHAP: -1.584)\",\n",
      "    \"- #3: Age - increases churn, moderate effect (SHAP: 0.412)\",\n",
      "    \"- #4: Used Special Discount Yes - increases churn, weak effect (SHAP: 0.183)\",\n",
      "    \"- #5: Internet Option Wi-Fi - increases churn, weak effect (SHAP: 0.174)\"\n",
      "  ],\n",
      "  \"explanation\": \"The prediction indicates this customer is unlikely to leave. Their membership category plays a crucial role in reducing churn. Additionally, they log in frequently, which also helps retain them. However, their age and use of special discounts slightly increase the risk of churn, along with their internet option.\",\n",
      "  \"shap_values\": {\n",
      "    \"gender_M\": 0.09423382580280304,\n",
      "    \"region_category_Town\": -0.04084346815943718,\n",
      "    \"region_category_Village\": 0.003045246470719576,\n",
      "    \"joined_through_referral_Yes\": 0.03610359504818916,\n",
      "    \"preferred_offer_types_Gift Vouchers/Coupons\": -0.05486419051885605,\n",
      "    \"preferred_offer_types_Without Offers\": -0.12203878164291382,\n",
      "    \"medium_of_operation_Desktop\": -0.027629755437374115,\n",
      "    \"medium_of_operation_Smartphone\": 0.06568849831819534,\n",
      "    \"internet_option_Mobile_Data\": 0.0022556763142347336,\n",
      "    \"internet_option_Wi-Fi\": 0.1736346036195755,\n",
      "    \"used_special_discount_Yes\": 0.18287909030914307,\n",
      "    \"offer_application_preference_Yes\": -0.03769388049840927,\n",
      "    \"past_complaint_Yes\": -0.049766357988119125,\n",
      "    \"years_since_joining\": 0.034610435366630554,\n",
      "    \"membership_category\": -8.527676582336426,\n",
      "    \"complaint_status\": 0.0005686234217137098,\n",
      "    \"age\": 0.4120582640171051,\n",
      "    \"days_since_last_login\": 0.14952506124973297,\n",
      "    \"avg_time_spent\": 0.14695948362350464,\n",
      "    \"avg_transaction_value\": 0.05626341700553894,\n",
      "    \"avg_frequency_login_days\": -1.5842729806900024,\n",
      "    \"points_in_wallet\": 0.13283847272396088\n",
      "  },\n",
      "  \"predicted_label\": 0\n",
      "}\n",
      "Demo: first row output\n",
      "{\n",
      "  \"top_features\": [\n",
      "    \"- #1 (MOST IMPORTANT): Membership Category - decreases churn, very strong effect (SHAP: -8.528)\",\n",
      "    \"- #2: Avg Frequency Login Days - decreases churn, strong effect (SHAP: -1.584)\",\n",
      "    \"- #3: Age - increases churn, moderate effect (SHAP: 0.412)\",\n",
      "    \"- #4: Used Special Discount Yes - increases churn, weak effect (SHAP: 0.183)\",\n",
      "    \"- #5: Internet Option Wi-Fi - increases churn, weak effect (SHAP: 0.174)\"\n",
      "  ],\n",
      "  \"explanation\": \"The prediction indicates this customer is unlikely to leave. Their membership category plays a crucial role in reducing churn. Additionally, they log in frequently, which also helps retain them. However, their age and use of special discounts slightly increase the risk of churn, along with their internet option.\",\n",
      "  \"shap_values\": {\n",
      "    \"gender_M\": 0.09423382580280304,\n",
      "    \"region_category_Town\": -0.04084346815943718,\n",
      "    \"region_category_Village\": 0.003045246470719576,\n",
      "    \"joined_through_referral_Yes\": 0.03610359504818916,\n",
      "    \"preferred_offer_types_Gift Vouchers/Coupons\": -0.05486419051885605,\n",
      "    \"preferred_offer_types_Without Offers\": -0.12203878164291382,\n",
      "    \"medium_of_operation_Desktop\": -0.027629755437374115,\n",
      "    \"medium_of_operation_Smartphone\": 0.06568849831819534,\n",
      "    \"internet_option_Mobile_Data\": 0.0022556763142347336,\n",
      "    \"internet_option_Wi-Fi\": 0.1736346036195755,\n",
      "    \"used_special_discount_Yes\": 0.18287909030914307,\n",
      "    \"offer_application_preference_Yes\": -0.03769388049840927,\n",
      "    \"past_complaint_Yes\": -0.049766357988119125,\n",
      "    \"years_since_joining\": 0.034610435366630554,\n",
      "    \"membership_category\": -8.527676582336426,\n",
      "    \"complaint_status\": 0.0005686234217137098,\n",
      "    \"age\": 0.4120582640171051,\n",
      "    \"days_since_last_login\": 0.14952506124973297,\n",
      "    \"avg_time_spent\": 0.14695948362350464,\n",
      "    \"avg_transaction_value\": 0.05626341700553894,\n",
      "    \"avg_frequency_login_days\": -1.5842729806900024,\n",
      "    \"points_in_wallet\": 0.13283847272396088\n",
      "  },\n",
      "  \"predicted_label\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate explanation for the first row only\n",
    "output_list = []\n",
    "\n",
    "# Get the first user_id\n",
    "first_user_id = X_test_sampled_with_id['id'].iloc[0]\n",
    "\n",
    "# Prepare input data\n",
    "result, shap_values = prepare_input_data(\n",
    "    first_user_id, parsed_json, json_structures\n",
    ")\n",
    "\n",
    "# Generate explanation\n",
    "output = generate_churn_explainability(\n",
    "    result=result,\n",
    "    shap_values=shap_values,\n",
    "    api_key=openai_api_key,\n",
    "    show_prompt=True\n",
    ")\n",
    "\n",
    "# Attach extra info\n",
    "output[\"shap_values\"] = shap_values\n",
    "output[\"predicted_label\"] = result\n",
    "\n",
    "# Store in list\n",
    "output_list.append(output)\n",
    "\n",
    "# Demo print\n",
    "print(\"Demo: first row output\")\n",
    "print(json.dumps(output, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a462c268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping to generate the LLM-generated narratives for SHAP explanations\n",
    "output_list = []\n",
    "\n",
    "# total number of samples\n",
    "n_samples = len(X_test_sampled_with_id)\n",
    "\n",
    "for idx, user_id in enumerate(X_test_sampled_with_id['id'], start=1):\n",
    "    result, shap_values = prepare_input_data(user_id, parsed_json, json_structures)\n",
    "\n",
    "    # Then generate explanations\n",
    "    output = generate_churn_explainability(\n",
    "        result=result,\n",
    "        shap_values=shap_values,\n",
    "        api_key=openai_api_key\n",
    "    )\n",
    "    \n",
    "    output[\"shap_values\"] = shap_values\n",
    "    output[\"predicted_label\"] = result\n",
    "    output_list.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3480f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = os.makedirs(\"../../data/output\", exist_ok=True)\n",
    "\n",
    "shap_output_df = pd.DataFrame.from_records(output_list)\n",
    "shap_output_df.to_csv(\"../../data/output/llm_generated_narratives_on_shap.csv.gz\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b59c95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_features</th>\n",
       "      <th>explanation</th>\n",
       "      <th>shap_values</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[- #1 (MOST IMPORTANT): Membership Category - ...</td>\n",
       "      <td>The model predicts this customer is unlikely t...</td>\n",
       "      <td>{'gender_M': 0.09423382580280304, 'region_cate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[- #1 (MOST IMPORTANT): Membership Category - ...</td>\n",
       "      <td>The prediction indicates this customer is like...</td>\n",
       "      <td>{'gender_M': -0.03530433401465416, 'region_cat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[- #1 (MOST IMPORTANT): Membership Category - ...</td>\n",
       "      <td>The prediction indicates this customer is like...</td>\n",
       "      <td>{'gender_M': -0.017987653613090515, 'region_ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        top_features  \\\n",
       "0  [- #1 (MOST IMPORTANT): Membership Category - ...   \n",
       "1  [- #1 (MOST IMPORTANT): Membership Category - ...   \n",
       "2  [- #1 (MOST IMPORTANT): Membership Category - ...   \n",
       "\n",
       "                                         explanation  \\\n",
       "0  The model predicts this customer is unlikely t...   \n",
       "1  The prediction indicates this customer is like...   \n",
       "2  The prediction indicates this customer is like...   \n",
       "\n",
       "                                         shap_values  predicted_label  \n",
       "0  {'gender_M': 0.09423382580280304, 'region_cate...                0  \n",
       "1  {'gender_M': -0.03530433401465416, 'region_cat...                1  \n",
       "2  {'gender_M': -0.017987653613090515, 'region_ca...                1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_output_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15a15881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check for the dimension of the shap_output_df\n",
    "shap_output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ad5497c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_label\n",
       "1    18\n",
       "0    12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure both target variable having equal distribution\n",
    "shap_output_df[\"predicted_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1760674a",
   "metadata": {},
   "source": [
    "## Part 3: LLM As A Judge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbbee34",
   "metadata": {},
   "source": [
    "### Prompt Template for LLM As A Judge\n",
    "\n",
    "```markdown\n",
    "# System Prompt\n",
    "You are an impartial judge and an expert in machine learning explainability.  \n",
    "Your task is to evaluate the alignment between a generated churn narrative and the provided SHAP values.\n",
    "\n",
    "You will receive:\n",
    "- The model prediction result\n",
    "- The customer's profile description\n",
    "- The top 5 SHAP values\n",
    "- A generated narrative to evaluate\n",
    "\n",
    "Your job is to check which features in the narrative align with the SHAP values in terms of **direction** (towards churn or away from churn) and **magnitude** (strong, weak, etc.).\n",
    "\n",
    "# User Prompt\n",
    "**[Context Data]**\n",
    "- Predicted Churn Result: <PREDICTED_LABEL> (0 = will not churn, 1 = will churn)\n",
    "- Top 5 SHAP Values: <TOP_5_SHAP_VALUES>\n",
    "\n",
    "**[Generated Narrative to Evaluate]**\n",
    "<GENERATED_NARRATIVE>\n",
    "\n",
    "Please return your evaluation in this format:\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"feature\": \"<feature_name>\",\n",
    "    \"feature_mentioned\": <True|False>,\n",
    "    \"direction_text\": \"<direction extracted from text_direction>\",\n",
    "    \"direction_shap\": \"<direction extracted from shap_direction_magnitude>\",\n",
    "    \"magnitude_shap\": \"<magnitude extracted from shap_direction_magnitude>\",\n",
    "    \"direction_match\": <True|False>,\n",
    "    \"magnitude_match\": <True|False>\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1aacb200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "prepare_for_judge_df = pd.read_csv('../../data/output/llm_generated_narratives_on_shap.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1bb04df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_features</th>\n",
       "      <th>explanation</th>\n",
       "      <th>shap_values</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['- #1 (MOST IMPORTANT): Membership Category -...</td>\n",
       "      <td>The model predicts this customer is unlikely t...</td>\n",
       "      <td>{'gender_M': 0.09423382580280304, 'region_cate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['- #1 (MOST IMPORTANT): Membership Category -...</td>\n",
       "      <td>The prediction indicates this customer is like...</td>\n",
       "      <td>{'gender_M': -0.03530433401465416, 'region_cat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['- #1 (MOST IMPORTANT): Membership Category -...</td>\n",
       "      <td>The prediction indicates this customer is like...</td>\n",
       "      <td>{'gender_M': -0.017987653613090515, 'region_ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        top_features  \\\n",
       "0  ['- #1 (MOST IMPORTANT): Membership Category -...   \n",
       "1  ['- #1 (MOST IMPORTANT): Membership Category -...   \n",
       "2  ['- #1 (MOST IMPORTANT): Membership Category -...   \n",
       "\n",
       "                                         explanation  \\\n",
       "0  The model predicts this customer is unlikely t...   \n",
       "1  The prediction indicates this customer is like...   \n",
       "2  The prediction indicates this customer is like...   \n",
       "\n",
       "                                         shap_values  predicted_label  \n",
       "0  {'gender_M': 0.09423382580280304, 'region_cate...                0  \n",
       "1  {'gender_M': -0.03530433401465416, 'region_cat...                1  \n",
       "2  {'gender_M': -0.017987653613090515, 'region_ca...                1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_for_judge_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d1deb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_for_judge_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4562dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 5 most important features from SHAP values\n",
    "import ast\n",
    "\n",
    "def get_top_shap_values_dict(shap_str, top_n=5):\n",
    "    # Convert string to dict if needed\n",
    "    if isinstance(shap_str, str):\n",
    "        shap_dict = ast.literal_eval(shap_str)\n",
    "    else:\n",
    "        shap_dict = shap_str\n",
    "    \n",
    "    # Sort by absolute values (largest to smallest), but keep original values\n",
    "    sorted_items = sorted(shap_dict.items(), key=lambda x: abs(x[1]), reverse=True)[:top_n]\n",
    "    \n",
    "    # Create dictionary with feature names and values\n",
    "    top_shap_dict = {}\n",
    "    for feature_name, value in sorted_items:\n",
    "        top_shap_dict[feature_name] = value\n",
    "    \n",
    "    return top_shap_dict\n",
    "\n",
    "prepare_for_judge_df['top_5_shap_values'] = prepare_for_judge_df['shap_values'].apply(\n",
    "        lambda x: get_top_shap_values_dict(x, top_n=5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1aafbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "def evaluate_narrative_with_llm(explanation_text, top_5_shap_values, predicted_label, show_prompt=False):\n",
    "    \"\"\"\n",
    "    Use OpenAI LLM as a judge to evaluate narrative quality feature-by-feature\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create magnitude mapping info for the judge\n",
    "    magnitude_info = \"\"\"\n",
    "    SHAP Magnitude Mapping (IMPORTANT - use this exact mapping):\n",
    "    - very strong: absolute value > 5\n",
    "    - strong: absolute value > 1 \n",
    "    - moderate: absolute value > 0.3\n",
    "    - weak: absolute value ≤ 0.3\n",
    "    \n",
    "    Direction Mapping:\n",
    "    - Positive SHAP value = \"towards churn\" \n",
    "    - Negative SHAP value = \"away from churn\"\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = f\"\"\"You are an impartial judge and an expert in machine learning explainability. \n",
    "Your task is to evaluate the alignment between a generated churn narrative and the provided SHAP values.\n",
    "\n",
    "{magnitude_info}\n",
    "\n",
    "You will receive:\n",
    "- The model prediction result\n",
    "- The top 5 SHAP values (ordered by importance, #1 most important first)\n",
    "- A generated narrative to evaluate\n",
    "\n",
    "Your job is to check which features in the narrative align with the SHAP values in terms of:\n",
    "\n",
    "1. **Direction Agreement (sign_agreement)**: \n",
    "   - True if the narrative direction matches SHAP direction\n",
    "   - False if they contradict\n",
    "\n",
    "2. **Ranking Agreement (rank_agreement)**: \n",
    "   - True if features appear in the narrative in roughly the same importance order as SHAP ranking\n",
    "   - False if a less important SHAP feature (#4, #5) is emphasized more than a more important one (#1, #2, #3)\n",
    "   - If feature is not mentioned, automatically False\n",
    "\n",
    "CRITICAL: Use the exact magnitude mapping provided above. Check SHAP values carefully against the thresholds.\n",
    "\"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "**[Context Data]**\n",
    "- Predicted Churn Result: {predicted_label} (0 = will not churn, 1 = will churn)\n",
    "- Top 5 SHAP Values (ordered by importance): {top_5_shap_values}\n",
    "\n",
    "**[Generated Narrative to Evaluate]**\n",
    "{explanation_text}\n",
    "\n",
    "Evaluate each of the top 5 SHAP features and return your evaluation in this format:\n",
    "\n",
    "```json\n",
    "[\n",
    "  {{\n",
    "    \"feature\": \"<exact_feature_name_from_shap>\",\n",
    "    \"feature_mentioned\": <True|False>,\n",
    "    \"direction_text\": \"<direction extracted from narrative text, or 'not mentioned'>\",\n",
    "    \"direction_shap\": \"<'towards churn' if SHAP > 0, 'away from churn' if SHAP < 0>\",\n",
    "    \"magnitude_shap\": \"<very strong|strong|moderate|weak using the mapping above>\",\n",
    "    \"sign_agreement\": <True if directions match, False if they contradict, False if not mentioned>,\n",
    "    \"rank_agreement\": <True if feature appears in appropriate importance order in text, False otherwise>\n",
    "  }},\n",
    "  ...\n",
    "]\n",
    "```\n",
    "\n",
    "IMPORTANT: \n",
    "- Evaluate ALL 5 SHAP features, even if not mentioned in the narrative\n",
    "- Use the exact magnitude thresholds provided\n",
    "- For rank_agreement: compare narrative emphasis order with SHAP importance ranking\n",
    "\"\"\"\n",
    "\n",
    "    # Initialize OpenAI client\n",
    "    client = OpenAI(api_key=openai_api_key)\n",
    "    \n",
    "    if show_prompt is True:\n",
    "        print(\"PROMPT TEMPLATE FOR evaluate_narrative_with_llm function\")\n",
    "        print(\"===========\")\n",
    "        print(\"# System Prompt\")\n",
    "        print(system_prompt)\n",
    "        print(\"\\n# User Prompt\")\n",
    "        print(user_prompt)\n",
    "        print(\"===========\")\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "            max_tokens=1500\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling OpenAI API: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13b713fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating first explanation only...\n",
      "PROMPT TEMPLATE FOR evaluate_narrative_with_llm function\n",
      "===========\n",
      "# System Prompt\n",
      "You are an impartial judge and an expert in machine learning explainability. \n",
      "Your task is to evaluate the alignment between a generated churn narrative and the provided SHAP values.\n",
      "\n",
      "\n",
      "    SHAP Magnitude Mapping (IMPORTANT - use this exact mapping):\n",
      "    - very strong: absolute value > 5\n",
      "    - strong: absolute value > 1 \n",
      "    - moderate: absolute value > 0.3\n",
      "    - weak: absolute value ≤ 0.3\n",
      "    \n",
      "    Direction Mapping:\n",
      "    - Positive SHAP value = \"towards churn\" \n",
      "    - Negative SHAP value = \"away from churn\"\n",
      "    \n",
      "\n",
      "You will receive:\n",
      "- The model prediction result\n",
      "- The top 5 SHAP values (ordered by importance, #1 most important first)\n",
      "- A generated narrative to evaluate\n",
      "\n",
      "Your job is to check which features in the narrative align with the SHAP values in terms of:\n",
      "\n",
      "1. **Direction Agreement (sign_agreement)**: \n",
      "   - True if the narrative direction matches SHAP direction\n",
      "   - False if they contradict\n",
      "\n",
      "2. **Ranking Agreement (rank_agreement)**: \n",
      "   - True if features appear in the narrative in roughly the same importance order as SHAP ranking\n",
      "   - False if a less important SHAP feature (#4, #5) is emphasized more than a more important one (#1, #2, #3)\n",
      "   - If feature is not mentioned, automatically False\n",
      "\n",
      "CRITICAL: Use the exact magnitude mapping provided above. Check SHAP values carefully against the thresholds.\n",
      "\n",
      "\n",
      "# User Prompt\n",
      "\n",
      "**[Context Data]**\n",
      "- Predicted Churn Result: 0 (0 = will not churn, 1 = will churn)\n",
      "- Top 5 SHAP Values (ordered by importance): {'membership_category': -8.527676582336426, 'avg_frequency_login_days': -1.5842729806900024, 'age': 0.4120582640171051, 'used_special_discount_Yes': 0.18287909030914307, 'internet_option_Wi-Fi': 0.1736346036195755}\n",
      "\n",
      "**[Generated Narrative to Evaluate]**\n",
      "The model predicts this customer is unlikely to leave, primarily due to their membership category, which significantly reduces churn risk. Additionally, their frequent logins further support retention. However, factors like age and the use of special discounts slightly increase the risk of churn, but their overall impact remains low.\n",
      "\n",
      "Evaluate each of the top 5 SHAP features and return your evaluation in this format:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"feature\": \"<exact_feature_name_from_shap>\",\n",
      "    \"feature_mentioned\": <True|False>,\n",
      "    \"direction_text\": \"<direction extracted from narrative text, or 'not mentioned'>\",\n",
      "    \"direction_shap\": \"<'towards churn' if SHAP > 0, 'away from churn' if SHAP < 0>\",\n",
      "    \"magnitude_shap\": \"<very strong|strong|moderate|weak using the mapping above>\",\n",
      "    \"sign_agreement\": <True if directions match, False if they contradict, False if not mentioned>,\n",
      "    \"rank_agreement\": <True if feature appears in appropriate importance order in text, False otherwise>\n",
      "  },\n",
      "  ...\n",
      "]\n",
      "```\n",
      "\n",
      "IMPORTANT: \n",
      "- Evaluate ALL 5 SHAP features, even if not mentioned in the narrative\n",
      "- Use the exact magnitude thresholds provided\n",
      "- For rank_agreement: compare narrative emphasis order with SHAP importance ranking\n",
      "\n",
      "===========\n",
      "PROMPT TEMPLATE FOR evaluate_narrative_with_llm function\n",
      "===========\n",
      "# System Prompt\n",
      "You are an impartial judge and an expert in machine learning explainability. \n",
      "Your task is to evaluate the alignment between a generated churn narrative and the provided SHAP values.\n",
      "\n",
      "\n",
      "    SHAP Magnitude Mapping (IMPORTANT - use this exact mapping):\n",
      "    - very strong: absolute value > 5\n",
      "    - strong: absolute value > 1 \n",
      "    - moderate: absolute value > 0.3\n",
      "    - weak: absolute value ≤ 0.3\n",
      "    \n",
      "    Direction Mapping:\n",
      "    - Positive SHAP value = \"towards churn\" \n",
      "    - Negative SHAP value = \"away from churn\"\n",
      "    \n",
      "\n",
      "You will receive:\n",
      "- The model prediction result\n",
      "- The top 5 SHAP values (ordered by importance, #1 most important first)\n",
      "- A generated narrative to evaluate\n",
      "\n",
      "Your job is to check which features in the narrative align with the SHAP values in terms of:\n",
      "\n",
      "1. **Direction Agreement (sign_agreement)**: \n",
      "   - True if the narrative direction matches SHAP direction\n",
      "   - False if they contradict\n",
      "\n",
      "2. **Ranking Agreement (rank_agreement)**: \n",
      "   - True if features appear in the narrative in roughly the same importance order as SHAP ranking\n",
      "   - False if a less important SHAP feature (#4, #5) is emphasized more than a more important one (#1, #2, #3)\n",
      "   - If feature is not mentioned, automatically False\n",
      "\n",
      "CRITICAL: Use the exact magnitude mapping provided above. Check SHAP values carefully against the thresholds.\n",
      "\n",
      "\n",
      "# User Prompt\n",
      "\n",
      "**[Context Data]**\n",
      "- Predicted Churn Result: 0 (0 = will not churn, 1 = will churn)\n",
      "- Top 5 SHAP Values (ordered by importance): {'membership_category': -8.527676582336426, 'avg_frequency_login_days': -1.5842729806900024, 'age': 0.4120582640171051, 'used_special_discount_Yes': 0.18287909030914307, 'internet_option_Wi-Fi': 0.1736346036195755}\n",
      "\n",
      "**[Generated Narrative to Evaluate]**\n",
      "The model predicts this customer is unlikely to leave, primarily due to their membership category, which significantly reduces churn risk. Additionally, their frequent logins further support retention. However, factors like age and the use of special discounts slightly increase the risk of churn, but their overall impact remains low.\n",
      "\n",
      "Evaluate each of the top 5 SHAP features and return your evaluation in this format:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"feature\": \"<exact_feature_name_from_shap>\",\n",
      "    \"feature_mentioned\": <True|False>,\n",
      "    \"direction_text\": \"<direction extracted from narrative text, or 'not mentioned'>\",\n",
      "    \"direction_shap\": \"<'towards churn' if SHAP > 0, 'away from churn' if SHAP < 0>\",\n",
      "    \"magnitude_shap\": \"<very strong|strong|moderate|weak using the mapping above>\",\n",
      "    \"sign_agreement\": <True if directions match, False if they contradict, False if not mentioned>,\n",
      "    \"rank_agreement\": <True if feature appears in appropriate importance order in text, False otherwise>\n",
      "  },\n",
      "  ...\n",
      "]\n",
      "```\n",
      "\n",
      "IMPORTANT: \n",
      "- Evaluate ALL 5 SHAP features, even if not mentioned in the narrative\n",
      "- Use the exact magnitude thresholds provided\n",
      "- For rank_agreement: compare narrative emphasis order with SHAP importance ranking\n",
      "\n",
      "===========\n",
      "\n",
      "Demo:\n",
      "=========\n",
      "\n",
      "Predicted Label:  0\n",
      "\n",
      "Explanation:  The model predicts this customer is unlikely to leave, primarily due to their membership category, which significantly reduces churn risk. Additionally, their frequent logins further support retention. However, factors like age and the use of special discounts slightly increase the risk of churn, but their overall impact remains low.\n",
      "\n",
      "Top 5 SHAP magnitudes:  {'membership_category': 'very strong', 'avg_frequency_login_days': 'strong', 'age': 'moderate', 'used_special_discount_Yes': 'weak', 'internet_option_Wi-Fi': 'weak'}\n",
      "\n",
      "Top 5 SHAP values:  {'membership_category': -8.527676582336426, 'avg_frequency_login_days': -1.5842729806900024, 'age': 0.4120582640171051, 'used_special_discount_Yes': 0.18287909030914307, 'internet_option_Wi-Fi': 0.1736346036195755}\n",
      "\n",
      "Evaluation:  {\n",
      "  \"completeness\": {\n",
      "    \"score\": 8.0\n",
      "  },\n",
      "  \"faithfulness\": {\n",
      "    \"score\": 8.0,\n",
      "    \"sign_points\": 4,\n",
      "    \"rank_points\": 4\n",
      "  },\n",
      "  \"raw_features\": [\n",
      "    {\n",
      "      \"feature\": \"membership_category\",\n",
      "      \"feature_mentioned\": true,\n",
      "      \"direction_text\": \"away from churn\",\n",
      "      \"direction_shap\": \"away from churn\",\n",
      "      \"magnitude_shap\": \"very strong\",\n",
      "      \"sign_agreement\": true,\n",
      "      \"rank_agreement\": true\n",
      "    },\n",
      "    {\n",
      "      \"feature\": \"avg_frequency_login_days\",\n",
      "      \"feature_mentioned\": true,\n",
      "      \"direction_text\": \"away from churn\",\n",
      "      \"direction_shap\": \"away from churn\",\n",
      "      \"magnitude_shap\": \"strong\",\n",
      "      \"sign_agreement\": true,\n",
      "      \"rank_agreement\": true\n",
      "    },\n",
      "    {\n",
      "      \"feature\": \"age\",\n",
      "      \"feature_mentioned\": true,\n",
      "      \"direction_text\": \"towards churn\",\n",
      "      \"direction_shap\": \"towards churn\",\n",
      "      \"magnitude_shap\": \"moderate\",\n",
      "      \"sign_agreement\": true,\n",
      "      \"rank_agreement\": true\n",
      "    },\n",
      "    {\n",
      "      \"feature\": \"used_special_discount_Yes\",\n",
      "      \"feature_mentioned\": true,\n",
      "      \"direction_text\": \"towards churn\",\n",
      "      \"direction_shap\": \"towards churn\",\n",
      "      \"magnitude_shap\": \"weak\",\n",
      "      \"sign_agreement\": true,\n",
      "      \"rank_agreement\": true\n",
      "    },\n",
      "    {\n",
      "      \"feature\": \"internet_option_Wi-Fi\",\n",
      "      \"feature_mentioned\": false,\n",
      "      \"direction_text\": \"not mentioned\",\n",
      "      \"direction_shap\": \"towards churn\",\n",
      "      \"magnitude_shap\": \"weak\",\n",
      "      \"sign_agreement\": false,\n",
      "      \"rank_agreement\": false\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Demo:\n",
      "=========\n",
      "\n",
      "Predicted Label:  0\n",
      "\n",
      "Explanation:  The model predicts this customer is unlikely to leave, primarily due to their membership category, which significantly reduces churn risk. Additionally, their frequent logins further support retention. However, factors like age and the use of special discounts slightly increase the risk of churn, but their overall impact remains low.\n",
      "\n",
      "Top 5 SHAP magnitudes:  {'membership_category': 'very strong', 'avg_frequency_login_days': 'strong', 'age': 'moderate', 'used_special_discount_Yes': 'weak', 'internet_option_Wi-Fi': 'weak'}\n",
      "\n",
      "Top 5 SHAP values:  {'membership_category': -8.527676582336426, 'avg_frequency_login_days': -1.5842729806900024, 'age': 0.4120582640171051, 'used_special_discount_Yes': 0.18287909030914307, 'internet_option_Wi-Fi': 0.1736346036195755}\n",
      "\n",
      "Evaluation:  {\n",
      "  \"completeness\": {\n",
      "    \"score\": 8.0\n",
      "  },\n",
      "  \"faithfulness\": {\n",
      "    \"score\": 8.0,\n",
      "    \"sign_points\": 4,\n",
      "    \"rank_points\": 4\n",
      "  },\n",
      "  \"raw_features\": [\n",
      "    {\n",
      "      \"feature\": \"membership_category\",\n",
      "      \"feature_mentioned\": true,\n",
      "      \"direction_text\": \"away from churn\",\n",
      "      \"direction_shap\": \"away from churn\",\n",
      "      \"magnitude_shap\": \"very strong\",\n",
      "      \"sign_agreement\": true,\n",
      "      \"rank_agreement\": true\n",
      "    },\n",
      "    {\n",
      "      \"feature\": \"avg_frequency_login_days\",\n",
      "      \"feature_mentioned\": true,\n",
      "      \"direction_text\": \"away from churn\",\n",
      "      \"direction_shap\": \"away from churn\",\n",
      "      \"magnitude_shap\": \"strong\",\n",
      "      \"sign_agreement\": true,\n",
      "      \"rank_agreement\": true\n",
      "    },\n",
      "    {\n",
      "      \"feature\": \"age\",\n",
      "      \"feature_mentioned\": true,\n",
      "      \"direction_text\": \"towards churn\",\n",
      "      \"direction_shap\": \"towards churn\",\n",
      "      \"magnitude_shap\": \"moderate\",\n",
      "      \"sign_agreement\": true,\n",
      "      \"rank_agreement\": true\n",
      "    },\n",
      "    {\n",
      "      \"feature\": \"used_special_discount_Yes\",\n",
      "      \"feature_mentioned\": true,\n",
      "      \"direction_text\": \"towards churn\",\n",
      "      \"direction_shap\": \"towards churn\",\n",
      "      \"magnitude_shap\": \"weak\",\n",
      "      \"sign_agreement\": true,\n",
      "      \"rank_agreement\": true\n",
      "    },\n",
      "    {\n",
      "      \"feature\": \"internet_option_Wi-Fi\",\n",
      "      \"feature_mentioned\": false,\n",
      "      \"direction_text\": \"not mentioned\",\n",
      "      \"direction_shap\": \"towards churn\",\n",
      "      \"magnitude_shap\": \"weak\",\n",
      "      \"sign_agreement\": false,\n",
      "      \"rank_agreement\": false\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Just evaluate the first explanation\n",
    "import re\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Evaluating first explanation only...\")\n",
    "\n",
    "first_row = prepare_for_judge_df.dropna(subset=['explanation']).iloc[0]\n",
    "\n",
    "evaluation = evaluate_narrative_with_llm(\n",
    "    first_row['explanation'],\n",
    "    first_row['top_5_shap_values'],\n",
    "    first_row['predicted_label'],\n",
    "    show_prompt=True\n",
    ")\n",
    "\n",
    "if evaluation:\n",
    "    try:\n",
    "        # Extract JSON inside ```json ... ```\n",
    "        match = re.search(r\"```json\\s*(\\[.*?\\])\\s*```\", evaluation, re.DOTALL)\n",
    "        if match:\n",
    "            clean_eval = match.group(1)\n",
    "        else:\n",
    "            clean_eval = evaluation.strip()\n",
    "\n",
    "        feature_data = json.loads(clean_eval)  # list of per-feature dicts\n",
    "\n",
    "        # ---- Compute faithfulness score (0–10) ----\n",
    "        sign_points = sum(1 for f in feature_data if f.get(\"sign_agreement\"))\n",
    "        rank_points = sum(1 for f in feature_data if f.get(\"rank_agreement\"))\n",
    "        correct_points = sign_points + rank_points\n",
    "        max_points = 2 * len(feature_data)\n",
    "        faithfulness_scores = (correct_points / max_points) * 10 if max_points > 0 else 0\n",
    "\n",
    "        # ---- Scale completeness (from LLM 1–5 → 1–10) ----\n",
    "        # If you already collect LLM completeness score in 1–5\n",
    "        # ---- Calculate completeness based on mentioned features ----\n",
    "        mentioned_features = sum(1 for f in feature_data if f.get(\"feature_mentioned\"))\n",
    "        completeness_raw = mentioned_features  # Count of features mentioned in text (0-5)\n",
    "        completeness_score_10 = round((completeness_raw / 5) * 10, 1)  # Scale to 0-10\n",
    "\n",
    "        # ---- Build eval_data summary ----\n",
    "        eval_data = {\n",
    "            \"completeness\": {\"score\": completeness_score_10},\n",
    "            \"faithfulness\": {\n",
    "                \"score\": round(faithfulness_scores, 1),\n",
    "                \"sign_points\": sign_points,\n",
    "                \"rank_points\": rank_points\n",
    "            },\n",
    "            \"raw_features\": feature_data\n",
    "        }\n",
    "\n",
    "        results.append({\n",
    "            'index': first_row.name,\n",
    "            'explanation': first_row['explanation'],\n",
    "            'predicted_label': first_row['predicted_label'],\n",
    "            \"top_5_shap_magnitudes\": {feature: map_shap_magnitude(value) for feature, value in first_row['top_5_shap_values'].items()},\n",
    "            \"top_5_shap_values\": first_row['top_5_shap_values'],\n",
    "            'evaluation': eval_data\n",
    "        })\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Failed to parse JSON for the first row, storing raw output.\")\n",
    "        results.append({\n",
    "            'index': first_row.name,\n",
    "            'evaluation': evaluation\n",
    "        })\n",
    "\n",
    "# Save results\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "print(\"\\nDemo:\\n=========\")\n",
    "print(\"\\nPredicted Label: \", evaluation_df[\"predicted_label\"][0])\n",
    "print(\"\\nExplanation: \", evaluation_df[\"explanation\"][0])\n",
    "print(\"\\nTop 5 SHAP magnitudes: \", evaluation_df[\"top_5_shap_magnitudes\"][0])\n",
    "print(\"\\nTop 5 SHAP values: \", evaluation_df[\"top_5_shap_values\"][0])\n",
    "print(\"\\nEvaluation: \", json.dumps(evaluation_df[\"evaluation\"][0], indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b3d43a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 30 explanations...\n",
      "Evaluating explanation 1/30\n",
      "Evaluating explanation 2/30\n",
      "Evaluating explanation 2/30\n",
      "Evaluating explanation 3/30\n",
      "Evaluating explanation 3/30\n",
      "Evaluating explanation 4/30\n",
      "Evaluating explanation 4/30\n",
      "Evaluating explanation 5/30\n",
      "Evaluating explanation 5/30\n",
      "Evaluating explanation 6/30\n",
      "Evaluating explanation 6/30\n",
      "Evaluating explanation 7/30\n",
      "Evaluating explanation 7/30\n",
      "Evaluating explanation 8/30\n",
      "Evaluating explanation 8/30\n",
      "Evaluating explanation 9/30\n",
      "Evaluating explanation 9/30\n",
      "Evaluating explanation 10/30\n",
      "Evaluating explanation 10/30\n",
      "Evaluating explanation 11/30\n",
      "Evaluating explanation 11/30\n",
      "Evaluating explanation 12/30\n",
      "Evaluating explanation 12/30\n",
      "Evaluating explanation 13/30\n",
      "Evaluating explanation 13/30\n",
      "Evaluating explanation 14/30\n",
      "Evaluating explanation 14/30\n",
      "Evaluating explanation 15/30\n",
      "Evaluating explanation 15/30\n",
      "Evaluating explanation 16/30\n",
      "Evaluating explanation 16/30\n",
      "Evaluating explanation 17/30\n",
      "Evaluating explanation 17/30\n",
      "Evaluating explanation 18/30\n",
      "Evaluating explanation 18/30\n",
      "Evaluating explanation 19/30\n",
      "Evaluating explanation 19/30\n",
      "Evaluating explanation 20/30\n",
      "Evaluating explanation 20/30\n",
      "Evaluating explanation 21/30\n",
      "Evaluating explanation 21/30\n",
      "Evaluating explanation 22/30\n",
      "Evaluating explanation 22/30\n",
      "Evaluating explanation 23/30\n",
      "Evaluating explanation 23/30\n",
      "Evaluating explanation 24/30\n",
      "Evaluating explanation 24/30\n",
      "Evaluating explanation 25/30\n",
      "Evaluating explanation 25/30\n",
      "Evaluating explanation 26/30\n",
      "Evaluating explanation 26/30\n",
      "Evaluating explanation 27/30\n",
      "Evaluating explanation 27/30\n",
      "Evaluating explanation 28/30\n",
      "Evaluating explanation 28/30\n",
      "Evaluating explanation 29/30\n",
      "Evaluating explanation 29/30\n",
      "Evaluating explanation 30/30\n",
      "Evaluating explanation 30/30\n"
     ]
    }
   ],
   "source": [
    "# Just evaluate all explanationsmp\n",
    "import re\n",
    "\n",
    "results = []\n",
    "\n",
    "print(f\"Evaluating {len(prepare_for_judge_df)} explanations...\")\n",
    "\n",
    "for idx, row in prepare_for_judge_df.iterrows():\n",
    "    if pd.isna(row['explanation']):\n",
    "        continue\n",
    "\n",
    "    print(f\"Evaluating explanation {idx+1}/{len(prepare_for_judge_df)}\")\n",
    "    \n",
    "    evaluation = evaluate_narrative_with_llm(\n",
    "        row['explanation'],\n",
    "        row['top_5_shap_values'],\n",
    "        row['predicted_label']\n",
    "    )\n",
    "\n",
    "    if evaluation:\n",
    "        try:\n",
    "            # Extract JSON inside ```json ... ```\n",
    "            match = re.search(r\"```json\\s*(\\[.*?\\])\\s*```\", evaluation, re.DOTALL)\n",
    "            if match:\n",
    "                clean_eval = match.group(1)\n",
    "            else:\n",
    "                clean_eval = evaluation.strip()\n",
    "\n",
    "            feature_data = json.loads(clean_eval)  # list of per-feature dicts\n",
    "\n",
    "            # ---- Compute \n",
    "            # score (0–10) ----\n",
    "            sign_points = sum(1 for f in feature_data if f.get(\"sign_agreement\"))\n",
    "            rank_points = sum(1 for f in feature_data if f.get(\"rank_agreement\"))\n",
    "            correct_points = sign_points + rank_points\n",
    "            max_points = 2 * len(feature_data)\n",
    "            faithfulness_scores = (correct_points / max_points) * 10 if max_points > 0 else 0\n",
    "\n",
    "            # ---- Scale completeness (from LLM 1–5 → 1–10) ----\n",
    "            mentioned_features = sum(1 for f in feature_data if f.get(\"feature_mentioned\"))\n",
    "            completeness_raw = mentioned_features  # Count of features mentioned in text (0-5)\n",
    "            completeness_score_10 = round((completeness_raw / 5) * 10, 1)  # Scale to 0-10\n",
    "\n",
    "            # ---- Build eval_data summary ----\n",
    "            eval_data = {\n",
    "                \"completeness\": {\"score\": completeness_score_10},\n",
    "                \"faithfulness\": {\n",
    "                    \"score\": round(faithfulness_scores, 1),\n",
    "                    \"sign_points\": sign_points,\n",
    "                    \"rank_points\": rank_points\n",
    "                },\n",
    "                \"raw_features\": feature_data\n",
    "            }\n",
    "\n",
    "            results.append({\n",
    "                'index': idx,\n",
    "                'explanation': row['explanation'],\n",
    "                'predicted_label': row['predicted_label'],\n",
    "                \"top_5_shap_magnitudes\": {feature: map_shap_magnitude(value) for feature, value in row['top_5_shap_values'].items()},\n",
    "                \"top_5_shap_values\": row['top_5_shap_values'],\n",
    "                'evaluation': eval_data\n",
    "            })\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Failed to parse JSON for row {idx}, storing raw output.\")\n",
    "            results.append({\n",
    "                'index': idx,\n",
    "                'evaluation': evaluation\n",
    "            })\n",
    "\n",
    "# Save results\n",
    "evaluation_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48c2b469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to '../../data/output/llm_judge_evaluation_results.csv.gz'\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "evaluation_df = pd.DataFrame(results)\n",
    "evaluation_df.to_csv('../../data/output/llm_judge_evaluation_results.csv.gz', index=False)\n",
    "\n",
    "print(\"Results saved to '../../data/output/llm_judge_evaluation_results.csv.gz'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b58523d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check the dimension of evaluation_df\n",
    "evaluation_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b125bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>explanation</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>top_5_shap_magnitudes</th>\n",
       "      <th>top_5_shap_values</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The model predicts this customer is unlikely t...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'membership_category': 'very strong', 'avg_fr...</td>\n",
       "      <td>{'membership_category': -8.527676582336426, 'a...</td>\n",
       "      <td>{'completeness': {'score': 8.0}, 'faithfulness...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The prediction indicates this customer is like...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'membership_category': 'strong', 'avg_frequen...</td>\n",
       "      <td>{'membership_category': 2.813594102859497, 'av...</td>\n",
       "      <td>{'completeness': {'score': 10.0}, 'faithfulnes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The prediction indicates this customer is like...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'membership_category': 'strong', 'avg_frequen...</td>\n",
       "      <td>{'membership_category': 3.10160756111145, 'avg...</td>\n",
       "      <td>{'completeness': {'score': 10.0}, 'faithfulnes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                        explanation  predicted_label  \\\n",
       "0      0  The model predicts this customer is unlikely t...                0   \n",
       "1      1  The prediction indicates this customer is like...                1   \n",
       "2      2  The prediction indicates this customer is like...                1   \n",
       "\n",
       "                               top_5_shap_magnitudes  \\\n",
       "0  {'membership_category': 'very strong', 'avg_fr...   \n",
       "1  {'membership_category': 'strong', 'avg_frequen...   \n",
       "2  {'membership_category': 'strong', 'avg_frequen...   \n",
       "\n",
       "                                   top_5_shap_values  \\\n",
       "0  {'membership_category': -8.527676582336426, 'a...   \n",
       "1  {'membership_category': 2.813594102859497, 'av...   \n",
       "2  {'membership_category': 3.10160756111145, 'avg...   \n",
       "\n",
       "                                          evaluation  \n",
       "0  {'completeness': {'score': 8.0}, 'faithfulness...  \n",
       "1  {'completeness': {'score': 10.0}, 'faithfulnes...  \n",
       "2  {'completeness': {'score': 10.0}, 'faithfulnes...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ff3dc0",
   "metadata": {},
   "source": [
    "## Part 4: Evaluation Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "388d9778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual Scores for Each Row:\n",
      "==================================================\n",
      "Row 1: Faithfulness = 8.0, Completeness = 8.0\n",
      "Row 2: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 3: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 4: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 5: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 6: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 7: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 8: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 9: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 10: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 11: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 12: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 13: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 14: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 15: Faithfulness = 8.0, Completeness = 10.0\n",
      "Row 16: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 17: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 18: Faithfulness = 7.0, Completeness = 8.0\n",
      "Row 19: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 20: Faithfulness = 8.0, Completeness = 10.0\n",
      "Row 21: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 22: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 23: Faithfulness = 7.0, Completeness = 8.0\n",
      "Row 24: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 25: Faithfulness = 9.0, Completeness = 10.0\n",
      "Row 26: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 27: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 28: Faithfulness = 10.0, Completeness = 10.0\n",
      "Row 29: Faithfulness = 6.0, Completeness = 8.0\n",
      "Row 30: Faithfulness = 10.0, Completeness = 10.0\n",
      "\n",
      "==================================================\n",
      "Summary Statistics:\n",
      "Average Faithfulness Score: 9.43\n",
      "Average Completeness Score: 9.73\n",
      "Faithfulness Score Range: 6.0 - 10.0\n",
      "Completeness Score Range: 8.0 - 10.0\n",
      "\n",
      "Detailed Scores DataFrame:\n",
      "    Row  Faithfulness_Score  Completeness_Score  Predicted_Label\n",
      "0     1                 8.0                 8.0                0\n",
      "1     2                10.0                10.0                1\n",
      "2     3                10.0                10.0                1\n",
      "3     4                10.0                10.0                0\n",
      "4     5                10.0                10.0                1\n",
      "5     6                10.0                10.0                1\n",
      "6     7                10.0                10.0                0\n",
      "7     8                10.0                10.0                0\n",
      "8     9                10.0                10.0                1\n",
      "9    10                10.0                10.0                1\n",
      "10   11                10.0                10.0                1\n",
      "11   12                10.0                10.0                1\n",
      "12   13                10.0                10.0                1\n",
      "13   14                10.0                10.0                0\n",
      "14   15                 8.0                10.0                1\n",
      "15   16                10.0                10.0                1\n",
      "16   17                10.0                10.0                0\n",
      "17   18                 7.0                 8.0                0\n",
      "18   19                10.0                10.0                1\n",
      "19   20                 8.0                10.0                0\n",
      "20   21                10.0                10.0                0\n",
      "21   22                10.0                10.0                0\n",
      "22   23                 7.0                 8.0                1\n",
      "23   24                10.0                10.0                0\n",
      "24   25                 9.0                10.0                0\n",
      "25   26                10.0                10.0                1\n",
      "26   27                10.0                10.0                1\n",
      "27   28                10.0                10.0                1\n",
      "28   29                 6.0                 8.0                1\n",
      "29   30                10.0                10.0                1\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Convert string representations of dicts to actual dicts if needed\n",
    "evaluation_df['evaluation'] = evaluation_df['evaluation'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Extract individual scores for each row\n",
    "faithfulness_scores = evaluation_df['evaluation'].apply(lambda x: x['faithfulness']['score']).values\n",
    "completeness_scores = evaluation_df['evaluation'].apply(lambda x: x['completeness']['score']).values\n",
    "\n",
    "# Print individual scores for each row\n",
    "print(\"Individual Scores for Each Row:\")\n",
    "print(\"=\" * 50)\n",
    "for idx, (faith, comp) in enumerate(zip(faithfulness_scores, completeness_scores)):\n",
    "    print(f\"Row {idx+1}: Faithfulness = {faith}, Completeness = {comp}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Summary Statistics:\")\n",
    "print(f\"Average Faithfulness Score: {faithfulness_scores.mean():.2f}\")\n",
    "print(f\"Average Completeness Score: {completeness_scores.mean():.2f}\")\n",
    "print(f\"Faithfulness Score Range: {faithfulness_scores.min():.1f} - {faithfulness_scores.max():.1f}\")\n",
    "print(f\"Completeness Score Range: {completeness_scores.min():.1f} - {completeness_scores.max():.1f}\")\n",
    "\n",
    "# Optional: Create a DataFrame for easier viewing\n",
    "scores_df = pd.DataFrame({\n",
    "    'Row': range(1, len(faithfulness_scores) + 1),\n",
    "    'Faithfulness_Score': faithfulness_scores,\n",
    "    'Completeness_Score': completeness_scores,\n",
    "    'Predicted_Label': evaluation_df['predicted_label'].values\n",
    "})\n",
    "\n",
    "print(\"\\nDetailed Scores DataFrame:\")\n",
    "print(scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9665ba71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "KEY STATISTICAL ANALYSIS\n",
      "============================================================\n",
      "\n",
      "1. SCORE DISTRIBUTIONS:\n",
      "----------------------------------------\n",
      "Faithfulness Score Distribution:\n",
      "6.0      1\n",
      "7.0      2\n",
      "8.0      3\n",
      "9.0      1\n",
      "10.0    23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Completeness Score Distribution:\n",
      "8.0      4\n",
      "10.0    26\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Key statistical analysis\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY STATISTICAL ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Score distributions\n",
    "print(\"\\n1. SCORE DISTRIBUTIONS:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"Faithfulness Score Distribution:\")\n",
    "faithfulness_counts = pd.Series(faithfulness_scores).value_counts().sort_index()\n",
    "print(faithfulness_counts)\n",
    "\n",
    "print(\"\\nCompleteness Score Distribution:\")\n",
    "completeness_counts = pd.Series(completeness_scores).value_counts().sort_index()\n",
    "print(completeness_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ae761a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. PERFORMANCE BY PREDICTED LABEL:\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Faithfulness_Score</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Completeness_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted_Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9.33</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>9.50</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.78</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Faithfulness_Score                           \\\n",
       "                               min  mean median   max count   \n",
       "Predicted_Label                                               \n",
       "0                              7.0  9.33   10.0  10.0    12   \n",
       "1                              6.0  9.50   10.0  10.0    18   \n",
       "\n",
       "                Completeness_Score                           \n",
       "                               min  mean median   max count  \n",
       "Predicted_Label                                              \n",
       "0                              8.0  9.67   10.0  10.0    12  \n",
       "1                              8.0  9.78   10.0  10.0    18  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 2. Performance by predicted label (most important)\n",
    "print(\"\\n2. PERFORMANCE BY PREDICTED LABEL:\")\n",
    "print(\"-\" * 40)\n",
    "label_analysis = pd.DataFrame({\n",
    "    'Predicted_Label': evaluation_df['predicted_label'].values,\n",
    "    'Faithfulness_Score': faithfulness_scores,\n",
    "    'Completeness_Score': completeness_scores\n",
    "})\n",
    "\n",
    "label_stats = label_analysis.groupby('Predicted_Label').agg({\n",
    "    'Faithfulness_Score': ['min', 'mean', 'median', 'max', 'count'],\n",
    "    'Completeness_Score': ['min', 'mean', 'median', 'max', 'count']\n",
    "}).round(2)\n",
    "label_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d5a9568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. HIGH-QUALITY EXPLANATIONS:\n",
      "----------------------------------------\n",
      "High faithfulness (≥8): 27/30 (90.0%)\n",
      "High completeness (≥8): 30/30 (100.0%)\n",
      "Both high (≥8): 27/30 (90.0%)\n"
     ]
    }
   ],
   "source": [
    "# 3. High-quality explanations count (business-relevant)\n",
    "print(\"\\n3. HIGH-QUALITY EXPLANATIONS:\")\n",
    "print(\"-\" * 40)\n",
    "high_faithfulness = (faithfulness_scores >= 8).sum()\n",
    "high_completeness = (completeness_scores >= 8).sum()\n",
    "both_high = ((faithfulness_scores >= 8) & (completeness_scores >= 8)).sum()\n",
    "\n",
    "print(f\"High faithfulness (≥8): {high_faithfulness}/{len(faithfulness_scores)} ({high_faithfulness/len(faithfulness_scores)*100:.1f}%)\")\n",
    "print(f\"High completeness (≥8): {high_completeness}/{len(completeness_scores)} ({high_completeness/len(completeness_scores)*100:.1f}%)\")\n",
    "print(f\"Both high (≥8): {both_high}/{len(faithfulness_scores)} ({both_high/len(faithfulness_scores)*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
