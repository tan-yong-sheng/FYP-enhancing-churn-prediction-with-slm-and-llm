{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5256849c",
   "metadata": {},
   "source": [
    "## Prepare the data for Human Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e1b4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "llm_narratives = pd.read_csv('../../data/output/llm_generated_narratives_on_shap.csv.gz', compression='gzip')\n",
    "llm_judge = pd.read_csv('../../data/output/llm_judge_evaluation_results.csv.gz', compression='gzip').drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a075c989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created evaluation dataset with 60 rows\n",
      "Columns: finished (True/False), human_evaluation (JSON)\n",
      "Saved to: ../../data/output/evaluation_data_shuffled.csv.gz\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "combined_llm_narratives_and_judge = pd.concat([llm_narratives, llm_judge], axis=1)\n",
    "combined_llm_narratives_and_judge.index = pd.RangeIndex(start=1, stop=len(combined_llm_narratives_and_judge)+1)\n",
    "\n",
    "def get_top_shap_values_dict(shap_str, top_n=5):\n",
    "    # Convert string to dict if needed\n",
    "    if isinstance(shap_str, str):\n",
    "        shap_dict = ast.literal_eval(shap_str)\n",
    "    else:\n",
    "        shap_dict = shap_str\n",
    "    \n",
    "    # Sort by absolute values (largest to smallest), but keep original values\n",
    "    sorted_items = sorted(shap_dict.items(), key=lambda x: abs(x[1]), reverse=True)[:top_n]\n",
    "    \n",
    "    # Create dictionary with feature names and values\n",
    "    top_shap_dict = {}\n",
    "    for feature_name, value in sorted_items:\n",
    "        top_shap_dict[feature_name] = value\n",
    "    \n",
    "    return top_shap_dict\n",
    "\n",
    "def sort_shap_values_by_abs(shap_str):\n",
    "    # Convert string to dict if needed\n",
    "    if isinstance(shap_str, str):\n",
    "        shap_dict = ast.literal_eval(shap_str)\n",
    "    else:\n",
    "        shap_dict = shap_str\n",
    "    \n",
    "    # Sort by absolute values (largest to smallest), but keep original values\n",
    "    sorted_items = sorted(shap_dict.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "    \n",
    "    # Return as dictionary\n",
    "    return dict(sorted_items)\n",
    "\n",
    "# Sort the main shap_values column by absolute values\n",
    "combined_llm_narratives_and_judge['shap_values'] = combined_llm_narratives_and_judge['shap_values'].apply(sort_shap_values_by_abs)\n",
    "\n",
    "# Add column for top 5 SHAP values as dictionary\n",
    "combined_llm_narratives_and_judge['top_5_shap_values'] = combined_llm_narratives_and_judge['shap_values'].apply(lambda x: get_top_shap_values_dict(x, top_n=5))\n",
    "\n",
    "# Add columns for human evaluation tracking\n",
    "combined_llm_narratives_and_judge['finished'] = False\n",
    "combined_llm_narratives_and_judge['human_evaluation'] = None  # Will store JSON evaluation data\n",
    "\n",
    "# Create evaluation copy with shuffled rows for random evaluation\n",
    "evaluation_data = combined_llm_narratives_and_judge.sample(frac=1, random_state=42).reset_index(drop=False)\n",
    "evaluation_data.rename(columns={'index': 'original_index'}, inplace=True)\n",
    "\n",
    "# Save both versions\n",
    "combined_llm_narratives_and_judge.to_csv(\"../../data/output/combined_llm_narratives_and_judge.csv.gz\", index=True)\n",
    "evaluation_data.to_csv(\"../../data/output/evaluation_data_shuffled.csv.gz\", index=True, compression='gzip')\n",
    "\n",
    "print(f\"Created evaluation dataset with {len(evaluation_data)} rows\")\n",
    "print(\"Columns: finished (True/False), human_evaluation (JSON)\")\n",
    "print(\"Saved to: ../../data/output/evaluation_data_shuffled.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d4f883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SAMPLE DATA ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shap_values</th>\n",
       "      <th>top_5_shap_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'membership_category': -8.010722160339355, 'a...</td>\n",
       "      <td>{'membership_category': -8.010722160339355, 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'membership_category': -8.259814262390137, 'a...</td>\n",
       "      <td>{'membership_category': -8.259814262390137, 'a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         shap_values  \\\n",
       "1  {'membership_category': -8.010722160339355, 'a...   \n",
       "2  {'membership_category': -8.259814262390137, 'a...   \n",
       "\n",
       "                                   top_5_shap_values  \n",
       "1  {'membership_category': -8.010722160339355, 'a...  \n",
       "2  {'membership_category': -8.259814262390137, 'a...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VERIFICATION: Check if sorting by absolute values works correctly ===\n",
      "\n",
      "Row 1:\n",
      "All SHAP values (sorted by abs):\n",
      "  1. membership_category: -8.0107 (abs: 8.0107)\n",
      "  2. avg_frequency_login_days: -3.1072 (abs: 3.1072)\n",
      "  3. year: -0.1845 (abs: 0.1845)\n",
      "  4. medium_of_operation_Desktop: -0.1695 (abs: 0.1695)\n",
      "  5. days_since_last_login: -0.1516 (abs: 0.1516)\n",
      "  6. points_in_wallet: -0.1434 (abs: 0.1434)\n",
      "  7. preferred_offer_types_Gift Vouchers/Coupons: 0.1286 (abs: 0.1286)\n",
      "  8. avg_transaction_value: -0.1206 (abs: 0.1206)\n",
      "Top 5 SHAP values:\n",
      "  1. membership_category: -8.0107 (abs: 8.0107)\n",
      "  2. avg_frequency_login_days: -3.1072 (abs: 3.1072)\n",
      "  3. year: -0.1845 (abs: 0.1845)\n",
      "  4. medium_of_operation_Desktop: -0.1695 (abs: 0.1695)\n",
      "  5. days_since_last_login: -0.1516 (abs: 0.1516)\n",
      "\n",
      "Row 2:\n",
      "All SHAP values (sorted by abs):\n",
      "  1. membership_category: -8.2598 (abs: 8.2598)\n",
      "  2. avg_frequency_login_days: -2.9948 (abs: 2.9948)\n",
      "  3. avg_time_spent: 0.2575 (abs: 0.2575)\n",
      "  4. points_in_wallet: 0.2389 (abs: 0.2389)\n",
      "  5. complaint_status: 0.2266 (abs: 0.2266)\n",
      "  6. preferred_offer_types_Without Offers: 0.2125 (abs: 0.2125)\n",
      "  7. offer_application_preference_Yes: 0.2073 (abs: 0.2073)\n",
      "  8. gender_M: -0.1410 (abs: 0.1410)\n",
      "Top 5 SHAP values:\n",
      "  1. membership_category: -8.2598 (abs: 8.2598)\n",
      "  2. avg_frequency_login_days: -2.9948 (abs: 2.9948)\n",
      "  3. avg_time_spent: 0.2575 (abs: 0.2575)\n",
      "  4. points_in_wallet: 0.2389 (abs: 0.2389)\n",
      "  5. complaint_status: 0.2266 (abs: 0.2266)\n",
      "\n",
      "=== SUMMARY ===\n",
      "✅ Removed top3_shap_values column\n",
      "✅ top_5_shap_values is now in dictionary format\n",
      "✅ Both shap_values and top_5_shap_values are ordered by largest absolute values\n",
      "✅ Original positive/negative signs are preserved\n",
      "\n",
      "=== COLUMNS IN DATASET ===\n",
      "Available columns: ['column_descriptions', 'meta_data_description', 'explanation', 'shap_values', 'predicted_label', 'generate_bad_narrative', 'evaluation', 'top_5_shap_values', 'finished', 'human_evaluation']\n"
     ]
    }
   ],
   "source": [
    "# Display the results\n",
    "print(\"=== SAMPLE DATA ===\")\n",
    "display(combined_llm_narratives_and_judge[['shap_values', 'top_5_shap_values']].head(2))\n",
    "\n",
    "print(\"\\n=== VERIFICATION: Check if sorting by absolute values works correctly ===\")\n",
    "for i in range(2):\n",
    "    print(f\"\\nRow {i+1}:\")\n",
    "    \n",
    "    # Get the shap values (should be sorted by abs value)\n",
    "    shap_vals = combined_llm_narratives_and_judge['shap_values'].iloc[i]\n",
    "    if isinstance(shap_vals, str):\n",
    "        shap_vals = ast.literal_eval(shap_vals)\n",
    "    \n",
    "    print(\"All SHAP values (sorted by abs):\")\n",
    "    for j, (feature, value) in enumerate(list(shap_vals.items())[:8]):  # Show first 8\n",
    "        print(f\"  {j+1}. {feature}: {value:.4f} (abs: {abs(value):.4f})\")\n",
    "    \n",
    "    # Get top 5\n",
    "    top_5 = combined_llm_narratives_and_judge['top_5_shap_values'].iloc[i]\n",
    "    if isinstance(top_5, str):\n",
    "        top_5 = ast.literal_eval(top_5)\n",
    "    \n",
    "    print(\"Top 5 SHAP values:\")\n",
    "    for j, (feature, value) in enumerate(top_5.items()):\n",
    "        print(f\"  {j+1}. {feature}: {value:.4f} (abs: {abs(value):.4f})\")\n",
    "\n",
    "print(f\"\\n=== SUMMARY ===\")\n",
    "print(f\"✅ Removed top3_shap_values column\")\n",
    "print(f\"✅ top_5_shap_values is now in dictionary format\")\n",
    "print(f\"✅ Both shap_values and top_5_shap_values are ordered by largest absolute values\")\n",
    "print(f\"✅ Original positive/negative signs are preserved\")\n",
    "print(f\"\\n=== COLUMNS IN DATASET ===\")\n",
    "print(\"Available columns:\", list(combined_llm_narratives_and_judge.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d85ca32",
   "metadata": {},
   "source": [
    "## Manual Evaluation Interface\n",
    "\n",
    "To evaluate LLM-generated narratives of ML SHAP explanations manually:\n",
    "\n",
    "- **Open gradio app**: At terminal of project root directory, run `python notebook/modeling/llm_evaluation_app.py` and then go to http://127.0.0.1:7860/ for the gradio app.\n",
    "- **Upload the data file**: Use the generated `evaluation_data_shuffled.csv.gz` from above\n",
    "- **Start evaluating**: Follow the on-screen instructions to complete evaluations\n",
    "- **Auto-backup**: Each evaluation automatically creates a backup file\n",
    "- **Final export**: Download the final CSV to replace the original data file\n",
    "\n",
    "**Features:**\n",
    "- ✅ Auto-save after each evaluation\n",
    "- ✅ Progress tracking and resume capability  \n",
    "- ✅ Randomized presentation order\n",
    "- ✅ Browser localStorage backup\n",
    "- ✅ Direct CSV export for `../../data/output/evaluation_data_shuffled.csv.gz`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
