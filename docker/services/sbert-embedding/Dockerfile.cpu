# Use an official Python runtime as a parent image
FROM python:3.10-slim

# Set environment variables
ENV PYTHONUNBUFFERED=1 \
    # Set HuggingFace cache directory inside the container
    HF_HOME=/app/.cache/huggingface \
    # Set Sentence Transformers cache directory
    SENTENCE_TRANSFORMERS_HOME=/app/.cache/sentence_transformers \
    # Set default model (can be overridden at runtime)
    SBERT_MODEL_NAME=all-MiniLM-L6-v2 \
    # Set default device
    SBERT_DEVICE=cpu \
    # FastAPI/Uvicorn settings
    HOST=0.0.0.0 \
    PORT=8000 \
    WORKERS=1 # Adjust based on CPU cores available to the container

# Set the working directory in the container
WORKDIR /app

# Install system dependencies if needed (e.g., build-essential for some packages)
# RUN apt-get update && apt-get install -y --no-install-recommends build-essential && rm -rf /var/lib/apt/lists/*

# Copy the requirements file into the container
COPY requirements.txt .

# Install Python dependencies
# Ensure onnxruntime (CPU version) is installed
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# Copy the application code into the container
COPY main.py .

# Make port 8000 available to the world outside this container
EXPOSE 8000

# Define the command to run the application using Uvicorn
# Use the number of workers defined by the environment variable
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "$WORKERS"]
